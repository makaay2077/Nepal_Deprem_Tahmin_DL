{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7326fed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akillisehir1\\AppData\\Local\\anaconda3\\envs\\bimtas\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (17,29,34,35,36,37,38,39,40,41,42,47,50) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\akillisehir1\\AppData\\Local\\anaconda3\\envs\\bimtas\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim Başlıyor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [01:14<04:56, 74.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.56421 | Train Acc: 72.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [02:37<03:57, 79.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002: | Train Loss: 0.55256 | Train Acc: 72.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [04:16<02:57, 88.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003: | Train Loss: 0.54960 | Train Acc: 73.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [06:07<01:37, 97.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004: | Train Loss: 0.54807 | Train Acc: 73.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [08:23<00:00, 100.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005: | Train Loss: 0.54695 | Train Acc: 73.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler,QuantileTransformer ,FunctionTransformer, LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader, TensorDataset,Dataset\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "damage_assessment=pd.read_csv('csv_building_damage_assessment.csv',sep=',') \n",
    "\n",
    "building_structure=pd.read_csv('csv_building_structure.csv',sep=',')\n",
    "\n",
    "# veri setlerini 'building_id', 'district_id', 'vdcmun_id', 'ward_id' sütunlarına göre birleştiriyoruz\n",
    "\n",
    "merge=damage_assessment.merge(building_structure , on=['building_id', 'district_id', 'vdcmun_id', 'ward_id'])\n",
    "\n",
    "#Belirli kolonlarda Nan şeklinde değer taşımayan kolanları siliyoruz\n",
    "merge.dropna(subset=['building_id','district_id', 'vdcmun_id', 'ward_id',\n",
    "            'has_geotechnical_risk_land_settlement', \n",
    "            'has_geotechnical_risk',\n",
    "           'has_geotechnical_risk_fault_crack',\n",
    "           'has_geotechnical_risk_liquefaction',\n",
    "           'has_geotechnical_risk_flood',\n",
    "           'has_geotechnical_risk_landslide',\n",
    "           'has_geotechnical_risk_rock_fall',\n",
    "           'has_geotechnical_risk_other',\n",
    "           'age_building',\n",
    "           'count_floors_pre_eq',\n",
    "           'plinth_area_sq_ft',\n",
    "           'land_surface_condition',\n",
    "           'has_superstructure_adobe_mud',\n",
    "           'has_superstructure_mud_mortar_stone',\n",
    "           'has_superstructure_stone_flag', \n",
    "           'has_superstructure_cement_mortar_stone',\n",
    "           'has_superstructure_mud_mortar_brick', \n",
    "           'has_superstructure_cement_mortar_brick',\n",
    "           'has_superstructure_timber',\n",
    "           'has_superstructure_bamboo', \n",
    "           'has_superstructure_rc_non_engineered',\n",
    "           'has_superstructure_rc_engineered',\n",
    "            'count_floors_pre_eq',\n",
    "           'count_floors_post_eq',\n",
    "           'height_ft_pre_eq',\n",
    "           'height_ft_post_eq',\n",
    "           'damage_grade_y',\n",
    "            ], inplace=True)\n",
    "\n",
    "\n",
    "#birleşik veri setinden belirli deprem öncesi bina , arazi , jeoteknik konularıyla ilgili kolonları seçerek devam ediyoruz\n",
    "merge= merge[['building_id','district_id', 'vdcmun_id', 'ward_id',\n",
    "    'has_geotechnical_risk',\n",
    "    'has_geotechnical_risk_land_settlement', \n",
    "           'has_geotechnical_risk_fault_crack',\n",
    "           'has_geotechnical_risk_liquefaction',\n",
    "           'has_geotechnical_risk_flood',\n",
    "           'has_geotechnical_risk_landslide',\n",
    "           'has_geotechnical_risk_rock_fall',\n",
    "           'has_geotechnical_risk_other',\n",
    "           'age_building',\n",
    "           'plinth_area_sq_ft',\n",
    "           'land_surface_condition',\n",
    "           'has_superstructure_adobe_mud',\n",
    "           'has_superstructure_mud_mortar_stone',\n",
    "           'has_superstructure_stone_flag', \n",
    "           'has_superstructure_cement_mortar_stone',\n",
    "           'has_superstructure_mud_mortar_brick', \n",
    "           'has_superstructure_cement_mortar_brick',\n",
    "           'has_superstructure_timber',\n",
    "           'has_superstructure_bamboo', \n",
    "           'has_superstructure_rc_non_engineered',\n",
    "           'has_superstructure_rc_engineered', \n",
    "           'count_floors_pre_eq',\n",
    "            'foundation_type',\n",
    "            'ground_floor_type',\n",
    "            'height_ft_pre_eq',\n",
    "           'damage_grade_y',\n",
    "          ]]\n",
    "\n",
    "\n",
    "\n",
    "#Bazı kolonların ismini değiştirdik\n",
    "merge=merge.rename(columns={'has_superstructure_adobe_mud':'adobe_mud',\n",
    "                           'has_superstructure_mud_mortar_stone':'mud_mortar_stone',\n",
    "                           'has_superstructure_stone_flag':'stone_flag',\n",
    "                            'has_superstructure_cement_mortar_brick':'cement_mortar_brick',\n",
    "                            'has_superstructure_cement_mortar_stone':'cement_mortar_stone',\n",
    "                           'has_superstructure_mud_mortar_brick':'mud_mortar_brick',\n",
    "                           'has_superstructure_timber':'timber',\n",
    "                           'has_superstructure_bamboo':'bamboo',\n",
    "                           'has_superstructure_rc_non_engineered':'rc_non_engineered',\n",
    "                            'has_superstructure_rc_engineered':'rc_engineered',\n",
    "                           'damage_grade_y':'damage_grade',\n",
    "                          })\n",
    "\n",
    "\n",
    "\n",
    "#damage_grade kolonundaki hasar derecerinden 3 ve üzeri olanlar orta - şiddetli hasarlı olandan yeni kolon oluşturduk\n",
    "merge[\"damage_grade\"] = merge[\"damage_grade\"].str[-1].astype(int)\n",
    "merge[\"severe_damage\"] = (merge[\"damage_grade\"] > 3).astype(int)  \n",
    "\n",
    "\n",
    "merge.drop(['building_id','damage_grade','district_id','vdcmun_id','ward_id'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "#veri setindeki kategorik olan verilere belirli sınıf değerleri atıyruz\n",
    "merge['land_surface_condition']=label_encoder.fit_transform(merge['land_surface_condition'].values.reshape(-1,1))\n",
    "merge['foundation_type']=label_encoder.fit_transform(merge['foundation_type'].values.reshape(-1,1))\n",
    "merge['ground_floor_type']=label_encoder.fit_transform(merge['ground_floor_type'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "#veriler  %90 eğitim %10 test verisi olarak ayırdık  \n",
    "X_train, X_test, y_train, y_test = train_test_split(merge.drop(columns=['severe_damage']),\n",
    "                                                    merge['severe_damage'],\n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state =9,\n",
    "                                                stratify=merge['severe_damage'])\n",
    "\n",
    "\n",
    "class DepremDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_dataset = DepremDataset(torch.from_numpy(X_train.to_numpy()).float(), torch.from_numpy(y_train.to_numpy()).long())\n",
    "test_dataset = DepremDataset(torch.from_numpy(X_test.to_numpy()).float(), torch.from_numpy(y_test.to_numpy()).long())\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001 \n",
    "NUM_FEATURES = len(X_train.columns)  #Öznitelik değerleri\n",
    "NUM_CLASSES = len(y_train.unique())  #Çıktı değerleri \n",
    "\n",
    "#Model mimarimizi oluşturduk\n",
    "\n",
    "class DepremModel(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(DepremModel, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = DepremModel(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "\n",
    "print(\"Eğitim Başlıyor\")\n",
    "for e in tqdm.tqdm(range(1, EPOCHS+1)):\n",
    "    \n",
    " \n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_dataloader:\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_train_pred = model(X_train_batch)\n",
    "\n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "\n",
    "\n",
    " \n",
    "   \n",
    "    # Kayıp ve doğruluk değerlerini yazdırıyoruz\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_dataloader):.5f} | Train Acc: {train_epoch_acc/len(train_dataloader):.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276cc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
